writeup v0
Â© 2015 George King. Permission to use this file is granted in ploy/license.txt.


# Goals

Ploy is an experiment, and broadly ambitious. Here are some of the topics that I'm interested in:


# Namespaces and Generic Functions

One major question is how generic functions work, and how they interact with namespaces interact. In particular I am interested in exploring the tension between extensibility of generic functions on the one hand, and static guarantees about correctness on the other. Furthermore, I am intrigued by the idea of defining type classes purely in terms of generic functions and their methods.

In Swift, imagine a protocol P in a library L, which specifies some requirement for a method M. Importing L just makes P visible; to make your class C implement P, you must define C.M, either immediately in the class definition, or else in some extension. Fundamentally, C.M is attached to C, not P. This presents several problems:
- If another protocol P1 specifies an unrelated requirement also named M, then the programmer cannot make C conform to both P and P1.
- If two different libraries define extensions on C implementing M, then the compiler fails with a redefinition conflict.
- Since the Swift type system employs inheritance, then adding implementations to intermediates in a typechain can cause subtle changes in behavior for subtypes. I believe that this concern applies to other subtyping mechanisms as well.

## Multiple Meanings Problem
Here, the same name M has two different meanings and needs to be disambiguated. The most obvious solution is to connect methods to the full path (the qualified name), rather than just the unqualified name symbol. The path then serves as the anchorpoint for all of its methods; it represents the intended meaning of the generic behavior, and locates that meaning at a single point.

## Multiple Implementations Problem
Here the function has multiple methods implemented for the same type. This is a problem when two different third parties implement a method for a preexisting type. At this point, I do not see a viable solution to this problem; it seems to be a fairly fundamental tension between extensibility and versus guarantees that code will be behave as originally intended. Here are two partial (probably unsatisfactory) solutions.

First, the language could provide a means for the application developer to "fix" the problem by explicitly deporting one of the implementations. However this only works if that deported implementation is non-critical to correctness (e.g., a custom description string formatter), and therefore is of only limited usefulness.

Second, the language could provide for some sort of "closed multifunction", meaning a overloaded/dispatched callable type that cannot be modified after definition. As a first approximation, a `multi-fn` would be defined simply as a set of functions, each with different argument type. For example:
| in L
| add = multi-fn # generic add function.
|   fn <Int Int>%Int ...; # Signed integer implementation.
|   fn <Uns Uns>%Uns ...; # Unsigned integer implementation.
| ;

This looks a lot like a traditional pattern-matching function; the main difference would be that it could be used to build a new, "extended" version of the function.
| in M
| use L
| add = multi-fn # extend add.
|   L/add
|   fn <Flt Flt>%Flt ...; # support floats too.
| ;

Essentially, `L/add` remains unaltered, while `M/add` combines the old and new methods (with whatever dispatch resolution rules the subtyping system might specify). Alternatively, we could make generic functions be extensible, but then have a form to produce a sealed version of a given function in order to guarantee correctness.

Either way, we end up with a compromise between regular, closed functions and open, extensible generic functions. I cannot think of a case where this actually buys the programmer anything useful; certainly the whole value of defining `add` as a generic is that it can be extended for unticipated data types.

## Type Classes

I am curious to see if it makes sense to define type classes purely in terms of these namespaced functions, meaning that a class specification would consist of a set of type parameters and a set of polyfunctions, each with an associated parameterization. For example, the Mapping class could be defined roughly as:
| generic-fn get (mapping:`T key:`K)%Opt^`V;
| class Mapping<Key Val>
|   impl get (mapping:This key:Key)%Opt^Val;;

`This` refers to whatever type is implementing `Mapping`; `Opt^Val` is the parameterization of the option type with `Val`. Crucially, `get` is a generic function, which can be defined in a namespace separate from Mapping; the type signature of `get` is simply a constraint on implementing methods, indicating the intended shape of the function signature.

Another consideration is to what extent can type conformance be implied/inferred. For example, should the Mapping class only include `get`, or should it also require a `set` method? Many would consider the class incomplete without `set`, but requiring it might force programmers to pointlessly implement `set` when they are really only interested in read-only behavior. This begins to sound like static duck typing (admittedly an ill-defined term); it would probably rely on a more serious type inference system. Even with inference, the language would probably also need some sort of notation for writing down anonymous class types as sets of implementation requirements, e.g.:
| class <Key Val>
|   impl get (mapping:This key:Key)%Opt^Val;
|   impl set (mapping:This key:Key val:Val)%<>;;


## Polymorphic Functions vs Generic Functions

Suppose that generic function `f` takes an arbitrary argument of type `\`T` and returns an `Int`; `g` takes one parameter and calls `f` on it:
| generic-fn f (`T)%Int;
| g = fn (`T)%Int f.$; # `g` simply returns the result of applying `f` to `$`.

This introduces an important distinction: `f` is a "generic function" in the sense that it is polymorphic and can have methods/overloads added to it; `g` on the other hand is a simple function that does whatever `f` does, and accepts whatever types `f` accepts. The mechanism by which the compiler achieves this is not yet defined.

The compiler could calculate that the `g` accepts any type for which there exists an overload of `f`, but this requires type inference between functions. The alternative is to create a named `class` definition, or an anonymous class specification as described above.

## Miscellaneous

It would be nice if generic accessors defaulted to accessing the same-named field of any such structure, or compound type.


# Fine Grained Dependency Calculation and Versioning

The scale of both software projects and programming language communities is continually growing. Managing dependencies is a cumbersome (sometimes intractible!) problem facing most professional developers today. One of the main appeals of functional programming is the emphasis on modularity, reducing interdependencies between various parts of the code. But apart from the internal algorithms of compilers, most tools are oblivious to the dependency structure of code. Version control has long been recognized as indespensible to professional programming, and yet the popular systems understand nothing of the actual program structure, only deltas between lines of text.

One design priority of Ploy is to enable automatic, useful calculations about code dependencies. Here are a few possible applications:

## Lazy Compilation

The cost of compiling a program should depend on the amount of code actually used by the program, not the taxonomic structure of all the code in all the libraries that the program references. To this end, all top/module-level syntactic definitions map directly to individual symbols. This allows the compiler to assemble a mapping from symbols to syntactic forms, which in turn allows it to only emit code for those symbols that are actually used by the program.

This design requires that global values have lazy initialization semantics, or else pure initializers free of side effects; Ploy currently uses lazy initialization for non-function values to fulfill this requirement. This should greatly reduce the time to compile; however currently all code in all source files must still be parsed. The grammar is simple, which should make the parser very fast; furthermore, it should be possible to cache parsing results to further reduce copmilation times.

## Dependency Queries

Given the above properties, it should be straightforward to ask the compiler to output structured information about which symbols depend on which other symbols. This could greatly facilitate reasoning about program architecture and studying unfamiliar codebases.

## Relief from Dependency Conflicts

Suppose a program A depends on libraries B and C, and that both B and C depend on a third library D. In most package management systems, if B and C specify incompatible version requirements for D, then the manager simply fails and A will not compile. Trying to include two different versions of D simultaneously leads to symbolic conflicts like redefinition and linker errors (note that some C libraries use prefix macro schemes to allow for the inclusion of multiple library versions in a single build). If the language versioned all public symbols by default then this sort of conflict would never occur.

How this works exactly remains to be determined, but the obvious first step is that every import statement specifies a specific version of its dependency. This approach stands in stark contrast to traditional systems (in which the build system and/or release package, not the source code, is responsible for the version), and to the community trend towards "semantic versioning", in which library developers make declarations of compatibility implied by the major/minor/patch version number distinctions.


## Generic Types

This is a huge topic, fairly conventional but almost certainly necessary.


## Metaprogramming

The Lisp community values macros as a key productivity tool. I'm very interested to see how useful macros might be in a statically compiled language like Ploy, and how well they interact with other language features. However they may be deferred until the compiler is self-hosting.


## Fault Tolerance

The LLVM community makes a strong distinction between programmer errors, which result in hard failures, and input errors, which can be recoverable. However the distinctions in practice often seem less-than-comprehensive. For example, in Swift an array out-of-bounds access is considered a programmer error, but a dictionary access with a missing key is guarded with an optional return value. While this decision seems fairly conventional, it means that these two collection types cannot be treated as instances of a more generic 'mapping' protocol. Thus the meaning of overloading the subscript operator is diminished, because the failure modes are not consistent. In other words, it seems that the failure behavior can also be an important, and often under-specified, aspect of generics.

I do appreciate the distinction between programmer and input errors, but I question whether hard failure in a complex system is the appropriate behavior. If a concurrent web server suffers an integer overflow while serving a single request, should it immediately die? What if doing so causes other in-progess transactions to canceled or possibly corrupted?

In contrast, high-level languages like Python make use of exceptions for regular control flow (e.g. StopIteration), which strikes me as an abuse of the very notion of an exceptional condition.

More research required!

## Effects System

Effects systems are an ineresting field but it will be some time before I can begin to explore this in the implementation.

I'm looking for some comfortable middle ground that allows the programmer to use imperative techniques while still enabling the compiler to prove things about program safety. For example, should simply logging to std-err change the type signature of a function from pure to impure?

